version: "3"
services:
  corenlp:
    image: 'sld3/corenlp:3.6.0'
    ports:
      - '9000:9000'
    restart: 'always'
    deploy:
      resources:
        limits:
          memory: 1024M

  opennmt:
    image: 'sld3/opennmt:latest'
    volumes:
      - './question_generation/data/:/root/data'
    command: bash -c "cd /root/opennmt && th tools/translation_server.lua -host 0.0.0.0 -port 5556  -model /root/data/model.t7  -beam_size 12"
    depends_on:
      - corenlp
    ports:
      - '5556:5556'
    restart: 'always'
    deploy:
      resources:
        limits:
          memory: 512M

  # opennmt_chitchat:
  #   image: 'sld3/opennmt:latest'
  #   volumes:
  #     - './opennmt_chitchat/data/:/root/data'
  #   command: bash -c "cd /root/opennmt && th tools/translation_server.lua -host 0.0.0.0 -port 5556  -model /root/data/8_40000_model_checkpoint.t7 -beam_size 12"
  #   ports:
  #     - '5557:5556'
  #   restart: 'no'

  bidaf:
    image: 'sld3/bi-att-flow:0.1.0'
    ports:
      - '1995:1995'
    restart: 'always'
    deploy:
      resources:
        limits:
          memory: 512M

  tf_chatbot:
    build:
      context: './tf_chatbot_seq2seq_antilm/'
    image: 'tf_chatbot:0.1.0'
    working_dir: '/src'
    command: python3 app.py --mode test --model_name example --vocab_size 100000 --size 256 --antilm 0.25
    ports:
      - '5000:5000'
    restart: 'always'
    volumes:
      - ./tf_chatbot_seq2seq_antilm:/src
    deploy:
      resources:
        limits:
          memory: 2048M

  dialog_tracker:
    build:
      context: './dialog_tracker/'
    image: 'dialog_tracker:1'
    command: python main.py prod
    restart: 'always'
    volumes:
      - ./dialog_tracker:/src
    depends_on:
      - corenlp
      - opennmt
      - tf_chatbot
    deploy:
      resources:
        limits:
          memory: 512M

